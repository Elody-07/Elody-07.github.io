title: 《信息检索导论》学习笔记——第2章
tags: 
  - 文本处理
categories: 
  - 笔记
date: 2018-3-22
---
> 继续学习《信息检索与导论》~今天只看到第二节，先发这两节的笔记。

<!--more-->

## 词项词典及倒排记录表
回顾构建倒排索引的几个主要步骤：
1. 收集需要建立索引的文档；
2. 对这些文档中的文本进行词条化；
3. 对第2步产生的词条进行语言学预处理，得到词项；
4. 根据词项对所有文档建立索引。

本章首先定义文档的基本组成单位并介绍在文档中确定这些单位所含字符序列的方法（2.1）。接着详细讨论在词条化和语言学预处理过程中所涉及到的主要的语言学相关问题，通过词条化和语言学预处理可以确定系统所用的词项词典（2.2）。构建索引的过程主要在第1章和第4章介绍。本章最后讨论倒排记录表的具体实现问题。2.3考察了一个扩展的带跳表倒排记录表数据结构，该结构能够支持查询的快速处理。2.4节主要介绍适合于处理短语查询和邻近查询的索引结构，这些查询在支持扩展布尔操作的检索系统和Web搜索系统中使用的十分普遍。

本章涉及到的部分术语：

|          术语          |                             解释                             |
| :--------------------: | :----------------------------------------------------------: |
| 词条化（tokenization） |        将原始的字符流转换成一个个词条（token）的过程         |
|      语言学预处理      | 建立词条的等价类，每个等价类对应一个词项，这些词项用于建立文档的索引 |
|         停用词         | 在文档和用户需求进行匹配时价值不大的常用词，需要彻底从词汇表中去除。 |

### 2.1 文档分析及编码转换

#### 2.1.1 字符序列的生成

文档处理的第一步是将文件中或者Web服务器上的字节序列转换成线性的字符序列。为了实现这种转换，首先要正确判断出文档的编码方式，可以将该过程看做一个基于机器学习的分类问题来处理，但在实际中往往通过**启发式方法**来实现，也可以利用文档的元信息或者直接由用户手工选择来确定。

> 启发式方法：指人在解决问题时所采取的一种根据经验规则进行发现的方法。其特点是在解决问题时,利用过去的经验,选择已经行之有效的方法，而不是系统地、以确定的步骤去寻求答案，与算法相对立。

在后面的讨论中，假设文档只由一系列的文本字符构成。

#### 2.1.2 文档单位的选择

对于长文档而言，存在“索引粒度”（indexing granularity）的问题。如果索引粒度太小，那么由于词项散布在多个细胞粒度文档中，我们就很可能错过那些重要的段落，即此时正确率高而召回率低；如果索引粒度太大，我们就很可能找到很多不相关的匹配结果，即正确率低而召回率高。索引粒度过大造成的问题可以通过采用显示或隐式的邻近搜索方法来缓解。

一个信息检索系统应该能够提供不同粒度索引的选项，在具体实施时如果要达到合理选择的目的，就必须要对文档集、用户及其可能的需求和使用模式等信息有一个非常深刻的理解。

在后面的讨论中，假设已经选择了合理的索引粒度。

### 2.2 词项集合的确定

#### 2.2.1 词条化

词条化是将给定的字符序列拆分成一系列子序列的过程，其中每个子序列称为一个词条（token）。在这个过程中会去掉一些特殊字符，如标点符号等。例如：

输入：Friends, Romans, Countrymen, lend me your ears；

输出：![](https://ws1.sinaimg.cn/large/006lJSqNly1fplvc5aounj30fu016jr6.jpg)

区分词条&词项：两者密切相关，但词项集合和词条集合可以完全不同。词项是通过对原始词条进行归一化得到的。

词条化的主要任务是确定哪些才是正确的词条。不管是输入布尔查询或者自由文本查询，为确保对文档和查询的同一字符串序列的处理结果一致，往往采用相同的词条化工具。

词条化处理必须知道文档的语言种类。由于大多数语言都有自己独特的特征模式，所以一种非常有效的语言种类识别方法（language identification）是利用短字符序列作为特征来分类（例子见书P18-19）。

#### 2.2.2 去除停用词

一个常用的生成停用词表的方法是将词项按照文档集频率从高到底排列，然后手工选择那些语义内容与文档主题关系不大的高频词作为停用词。停用词表中的每个词将在索引过程中被忽略，可以大大减小系统所需存储的倒排记录表的数目。但是，对于短语查询，停用词表的使用可能增大搜索难度，比如歌名或者著名诗歌片段全由常用的停用词组成（如To be or not to be, Let it Be等）。

在信息检索系统不断发展的历程中，有从大停用词表（200-300个词）到小停用词表（7-12个词）最后到不用停用词的趋势。**Web搜索引擎通常不用停用词表**。一些现代IR系统更关注如何利用语言的统计特性来更好地处理常见词问题，因此不论是对索引大小还是查询处理的时间而言，不去除停用词所增加的开销并没有那么大。

#### 2.2.3 词项归一化

词条归一化（token normalization）是将看起来不完全一致的多个词条归纳成一个等价类。最常规的做法是隐式地建立等价类，每类可以用其中的某个元素来命名（如将anti-discriminatory和antidiscriminatory映射成词项antidiscriminatory）。

另一种建立等价类的方法是维持多个非归一化词条之间的关联关系（如car和automobile），该方法可以扩展成手工建立同义词词表。这些词项之间的关系可以通过两种方式来实现。常用的方式是采用非归一化的词条进行索引，并为某个查询项维护一张包含多个词的**查询扩展词表**。当输入一个查询词项时，则根据扩展词表行扩展并将扩展后得到的多个词所对应的倒排记录表合在一起。另一种方式是在索引构建时就对词进行扩展。这两种方式虽然相对隐式建立等价类来说效率低，但是更具灵活性。

一些在实际中会遇到的词条归一化问题及其对策：

**1. 重音及变音符号问题**

**2. 大小写转换问题**

一般策略是将所有的字母转换成小写，但有些专有名词由普通名词构成，因此大小写不同则意义不同，并且这种意义不同只能通过大小写来区别。

对英语来说，大小写处理的另一种做法是只将部分词条转换成小写形式。最简单的启发式处理方法是将句首词或标题中大写词转换成小写形式，句中的大写词仍保留原来的形式。对于上述工作，也可以采用机器学习序列模型，基于多种特征实现更精确的大小写决策。

然而实际中，用户常常忽略大小写而使用小写方式输入查询，因此通常采用全部转换成小写的做法。

**3. 英语中的其他问题**

英语中还存在一些独特的归一化做法。如英式英语和美式英语拼写的统一，日期、时间等多种形式的表达等给归一化造成了额外的负担。

**4.其他语言的问题**

待索引的文档集可以同时包括来自不同语言的文档，单篇文档中也可能同时出现不同语言的文本。一个普遍的做法是，先判定语言种类，然后采用该语言的词条化和归一化规则在预定的粒度（如整篇文档或者每个段落）水平上进行处理。

当文档集包含多个语言时，单个索引中可能要包含来自不同语言的词项，一种做法是在文档上运行一个语言识别器，然后将每个词项的语言种类标记在词项词典中。

当处理外来词或者复合词时，拼写不明确或者在不同的音译标准下会产生不同拼写结果。处理此类情况的一种做法是采用启发式方法建立等价类，或者根据发音相同来进行词项扩展。

#### 2.2.4 词干还原和词形归并

出于语法要求，文档中常出现词的不同形态，语言中也存在大量意义相近的同源词。在很多情况下，希望输入其中一个词能返回包含其同源词的文档。

词干还原和词形归并的目的都是减少词的屈折变化形式，并且有时会将派生词转化为基本形式，如am, are, is → be等。

区分*词干还原（stemming）*&*词形归并（lemmatization）*：前者通常指一个很粗略的去除单词两端词缀的启发式过程，通常也包括去除派生词缀；而后者通常指利用词汇表和词形分析来去除屈折词缀，从而返回词的原形或词典中的词的过程，返回的结果称为*词元（lemma）*。这两个过程的区别还在于：词干还原在一般情况下会将多个派生相关词合并在一起，而词形归并通常只将同一词元的不同屈折形式进行合并。二者常通过在索引过程中增加插件程序的方式实现。

